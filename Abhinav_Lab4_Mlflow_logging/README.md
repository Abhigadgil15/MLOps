# ğŸš€ MLflow Experiment Tracking Guide

> A comprehensive guide demonstrating MLflow's experiment tracking capabilities with machine learning models from basic tracking to advanced hyperparameter tuning.

---

## ğŸ“‹ Prerequisites

Install required dependencies:

```bash
pip install mlflow scikit-learn tensorflow matplotlib seaborn pandas numpy
```

---

## ğŸ¯ Quick Start

### Running the Experiments

Execute the code blocks in sequence:

### ğŸ“Š Block 1: Setup and Visualizations

```bash
python MLflow_Setup_and_Basic_Stats.py
```

**What it does:** 

Generates dataset statistics, feature distributions, correlation heatmaps, and pairwise relationships for the Iris dataset.

---

### ğŸ” Block 2: Basic MLflow Tracking

```bash
python MLflow_Basic_Tracking.py
```

**What it does:** 

Demonstrates fundamental MLflow concepts - logging parameters, metrics over multiple steps, and artifacts.

---

### ğŸ“ Block 3: Logistic Regression with Scaling

```bash
python MLflow_Logistic_Regression.py
```

**What it does:** 

Complete logistic regression pipeline with data scaling, confusion matrix visualization, and comprehensive metrics logging. 

**Fixes convergence issues** through proper preprocessing.

---

### âš¡ Block 4: Autologging Example

```bash
python MLflow_Autologging.py
```

**What it does:** 

Shows MLflow's autologging feature that automatically captures model parameters, metrics, and artifacts with minimal code. 

Includes model loading and inference examples.

---

### ğŸ§  Block 5: Keras Neural Network (MNIST)

```bash
python MLflow_Keras_MNIST.py
```

**What it does:** 

Deep learning example using TensorFlow/Keras on MNIST dataset. 

Demonstrates autologging for neural networks with training history visualization.

---

### ğŸ”¬ Block 6: GridSearch with Random Forest

```bash
python MLflow_GridSearch_RF.py
```

**What it does:** 

Advanced hyperparameter tuning using GridSearchCV with nested runs. 

Includes comprehensive visualizations: heatmaps of parameter combinations, feature importance, and performance metrics.

---

## ğŸ–¥ï¸ Viewing Results

Start the MLflow UI to visualize and compare experiments:

```bash
mlflow ui
```

Then open your browser to: **http://localhost:5000**

---

## âœ¨ Key Improvements Made

### ğŸ”§ Convergence Fixes

- âœ… Increased `max_iter` from 1 to 1000 in LogisticRegression

- âœ… Implemented `StandardScaler` for feature normalization

- âœ… Proper solver configuration to prevent convergence warnings

### ğŸ’¾ Model Persistence

- âœ… Dynamic `run_id` retrieval for model loading

- âœ… Correct URI formatting (`runs:/{run_id}/model`)

- âœ… Scaler artifacts saved alongside models for inference

### ğŸ†• Modern API Usage

- âœ… Updated Keras to use `Input` layer instead of deprecated `input_shape` parameter

- âœ… Compatible with TensorFlow 2.x and Keras 3.x

- âœ… Proper warning suppression for version compatibility

### ğŸ“ˆ Enhanced Logging

- âœ… Nested runs for GridSearch trials (parent-child relationships)

- âœ… Comprehensive artifact logging (plots, reports, model files)

- âœ… Multi-dimensional metric tracking (train/test accuracy, overfitting gaps)

---

## ğŸ“Š Visualizations Generated

Each experiment creates informative visualizations automatically:

| Visualization Type | Description |
|-------------------|-------------|
| ğŸ¨ **Feature Analysis** | Distribution plots, correlation matrices, pairplots |
| ğŸ“‰ **Model Performance** | Confusion matrices, classification reports |
| ğŸ“ˆ **Training Progress** | Accuracy/loss curves for neural networks |
| ğŸ”¥ **Hyperparameter Tuning** | GridSearch heatmaps, parameter importance |
| ğŸŒŸ **Feature Engineering** | Feature importance rankings |

---

## ğŸ“ Project Structure

```
mlflow-experiments/
â”‚
â”œâ”€â”€ ğŸ“‚ mlruns/                           # MLflow tracking directory (auto-generated)
â”‚   â”œâ”€â”€ 0/                               # Default experiment
â”‚   â”œâ”€â”€ .trash/                          # Deleted runs
â”‚   â””â”€â”€ experiments/                     # Experiment metadata
â”‚
â”œâ”€â”€ ğŸ“‚ artifacts/                        # Generated visualizations and models
â”‚   â”œâ”€â”€ feature_distributions.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ training_history.png
â”‚   â””â”€â”€ gridsearch_heatmap.png
â”‚
â”œâ”€â”€ ğŸ“„ MLflow_Setup_and_Basic_Stats.py  # Dataset exploration and stats
â”œâ”€â”€ ğŸ“„ MLflow_Basic_Tracking.py         # Simple tracking example
â”œâ”€â”€ ğŸ“„ MLflow_Logistic_Regression.py    # Classification with preprocessing
â”œâ”€â”€ ğŸ“„ MLflow_Autologging.py            # Automatic logging demo
â”œâ”€â”€ ğŸ“„ MLflow_Keras_MNIST.py            # Deep learning example
â”œâ”€â”€ ğŸ“„ MLflow_GridSearch_RF.py          # Hyperparameter optimization
â”‚
â””â”€â”€ ğŸ“– README.md                         # This file
```

---

## ğŸ› ï¸ MLflow CLI Commands

Essential commands for managing experiments:

```bash
# ğŸš€ Start UI on default port
mlflow ui

# ğŸ”Œ Start UI on custom port
mlflow ui --port 5001

# ğŸ’¾ Specify backend storage location
mlflow ui --backend-store-uri ./mlruns

# ğŸ“‹ List all experiments
mlflow experiments list

# ğŸ” Search runs with filters
mlflow runs list --experiment-id 1

# ğŸ—‘ï¸ Delete an experiment (moves to .trash)
mlflow experiments delete --experiment-id <ID>

# â™»ï¸ Restore deleted experiment
mlflow experiments restore --experiment-id <ID>
```

---

## ğŸ’¡ Tips for Effective Demonstrations

**1. ğŸ“š Sequential Execution**

Run blocks 1-6 in order to show progression from basic to advanced concepts

**2. ğŸ‘€ Real-time Monitoring**

Keep MLflow UI open in browser while running experiments to see live updates

**3. âš–ï¸ Comparative Analysis**

Use the "Compare" feature in UI to analyze multiple runs side-by-side

**4. ğŸ“¤ Export Capabilities**

Download charts and reports directly from the UI for presentations

**5. ğŸ”— Nested Organization**

GridSearch example shows how to structure complex experiments with parent-child runs

**6. ğŸ“¦ Artifact Management**

All plots and models are versioned and retrievable through the UI

---

## ğŸ“š What Each Block Demonstrates

| Block | ğŸ¯ Concept | ğŸ’ Key Takeaway |
|-------|-----------|----------------|
| **1** | Data Exploration | Understanding dataset before modeling |
| **2** | Basic Tracking | Manual logging of params, metrics, artifacts |
| **3** | Full Pipeline | Preprocessing + training + evaluation |
| **4** | Autologging | Minimal code, maximum tracking |
| **5** | Deep Learning | Neural network tracking with Keras |
| **6** | Optimization | Systematic hyperparameter search with nested runs |

---

## ğŸ”§ Troubleshooting

### âš ï¸ Port already in use

```bash
mlflow ui --port 5001  # Use different port
```

### â“ Cannot find experiment

```bash
mlflow experiments list  # Verify experiment exists
```

### ğŸš« Model loading fails

- âœ… Ensure you're using the correct `run_id` from the MLflow UI

- âœ… Check that the artifact path is `model` not `models`

- âœ… Verify the experiment hasn't been deleted

### ğŸ“¦ Import errors

```bash
# Check installed packages
pip list | grep mlflow

# Use virtual environment to avoid conflicts
python -m venv mlflow_env
source mlflow_env/bin/activate  # On Windows: mlflow_env\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸŒ Additional Resources

- ğŸ“– [MLflow Documentation](https://mlflow.org/docs/latest/index.html)

- ğŸ” [MLflow Tracking API](https://mlflow.org/docs/latest/tracking.html)

- ğŸ¤– [Scikit-learn Integration](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html)

- ğŸ§  [TensorFlow/Keras Integration](https://mlflow.org/docs/latest/python_api/mlflow.keras.html)

---

## ğŸ“ Notes

> **ğŸ’¡ Tip:** The `mlruns` directory is created automatically when you run your first experiment. All experiment data, metrics, parameters, and artifacts are stored here by default.

> **âš ï¸ Warning:** Don't manually edit files in the `mlruns` directory as it may corrupt your experiment data.

---

<div align="center">

### ğŸ‰ Happy Tracking with MLflow! ğŸ‰

Made with â¤ï¸ for ML Engineers

</div>
